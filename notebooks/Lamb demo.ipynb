{
 "metadata": {
  "name": "",
  "signature": "sha256:1a35fd15904a7937a2b41837724fccf29241a9dbe1bd65323657acc0ddf903ae"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Lamb demo v. 0.9\n",
      "##Author: Kyle Rawlins\n",
      "\n",
      "Last updated April, 2014. History:\n",
      "\n",
      " * 0.5: first version\n",
      " * 0.6: updated to work with refactored class hierarchy (Apr 2013)\n",
      " * 0.6.1: small fixes to adapt to changes in various places (Sep 2013)\n",
      " * 0.7: various fixes to work with alpha release (Jan 2014)\n",
      " * 0.9: substantial updates, merge content from LSA poster (Apr 2014)\n",
      " \n",
      "To run through this demo, use shift-enter (runs and moves to next cell).  If you run things out of order, you may encounter problems (missing variables etc.)\n",
      "\n",
      "Note: this should always be saved in the repository without output."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from lamb.types import TypeMismatch, type_e, type_t, type_property\n",
      "from lamb.lang import te\n",
      "from lamb.utils import ltx_print\n",
      "from lamb.meta import TypedTerm, TypedExpr, LFun, CustomTerm\n",
      "reload_lamb()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Just some basic configuration\n",
      "meta.constants_use_custom(False)\n",
      "lang.bracket_setting = lang.BRACKET_FANCY"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# First pitch\n",
      "\n",
      "Have you ever wanted to type something like this in, and have it actually do something?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%lamb\n",
      "||every|| = \u03bb f_<e,t> : \u03bb g_<e,t> : Forall x_e : f(x) >> g(x)\n",
      "||student|| = L x_e : Student(x)\n",
      "||danced|| = L x_e : Danced(x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r = ((every * student) * danced)\n",
      "r"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Two problems in formal semantics #\n",
      "\n",
      "1. Type-driven computation could be a lot easier to visualize and check.  (Q: could it be made too easy?)\n",
      "\n",
      "2. Grammar fragments as in Montague Grammar: good idea in principle, hard to use in practice.\n",
      "\n",
      "  * A **fragment** is a *complete* formalization of *sublanguage* consisting of the *key relevant phenomena* for the problem at hand.  (Potential problem-points italicized.)\n",
      "\n",
      "Solution: a system for developing interactive fragments: \"*IPython Lambda Notebook*\"\n",
      "\n",
      "* Creator can work interactively with analysis -- accelerate development, limit time spent on tedious details.\n",
      "* Reader can explore derivations in ways that are not typically possible in typical paper format.\n",
      "* Creator and reader can be certain that derivations work, verified by the system.\n",
      "* Bring closer together formal semantics and computational modeling.\n",
      "\n",
      "Inspired by:\n",
      "\n",
      " * Von Eijck and Unger (2013): implementation of compositional semantics in Haskell.  No interface (beyond standard Haskell terminal); great if you like Haskell.  Introduced the idea of a fragment in digital form.\n",
      " * UPenn Lambda calculator (Champollion, Tauberer, and Romero 2007): teaching oriented.  (Now under development again.)\n",
      " * `nltk.sem`: implementation of the lambda calculus with a typed metalanguage, interface with theorem provers.  No interactive interface.\n",
      " * Jealousy of R studio, Matlab, Mathematica, etc.\n",
      "\n",
      "### The role of formalism & fragments ###\n",
      "\n",
      "What does *formal* mean in semantics?  What properties should a theory have?\n",
      "\n",
      " 1. Mathematically precise (lambda calculus, type theory, logic, model theory(?), ...)\n",
      " 2. Complete (covers \"all\" the relevant data).\n",
      " 3. Predictive (like any scientific theory).\n",
      " 4. Consistent, or at least compatible (with itself, analyses of other phenomena, some unifying conception of the grammar).\n",
      " \n",
      "The *method of fragments* (Partee 1979, Partee and Hendriks 1997) provides a structure for meeting these criteria.\n",
      "\n",
      " * Paper with a fragment provides a working system.  (Probably.)\n",
      " * Explicit outer bound for empirical coverage.\n",
      " * Integration with a particular theory of grammar.  (To some extent.)\n",
      " * Explicit answer to many detailed questions not necessarily dealt with in the text.\n",
      " \n",
      "**Claim**: fragments are a method of replicability, similar to a computational modeller providing their model.\n",
      "\n",
      " * To be clear, a fragment is neither necessary nor sufficient for having a good theory / analysis / paper...\n",
      "\n",
      "Additional benefit: useful internal check for researcher.\n",
      "\n",
      ">\"...But I feel strongly that it is important to try to [work with fully explicit fragments] periodically, because otherwise it is extremely easy to think that you have a solution to a problem when in fact you don't.\" (Partee 1979, p. 41)\n",
      "\n",
      "### The challenges of fragments\n",
      "\n",
      "Part 1 of the above quote:\n",
      "\n",
      ">\"It can be very frustrating to try to specify frameworks and fragments explicitly; this project has not been entirely rewarding.  I would not recommend that one always work with the constraint of full explicitness.\" (Ibid.)\n",
      "\n",
      " * Fragments can be tedious and time-consuming to write (not to mention hard).\n",
      " * Fragments as traditionally written are in practice not easy for a reader to use.\n",
      " \n",
      "   - Dense/unapproachable.  With exactness can come a huge chunk of hard-to-digest formalism.  E.g. Partee (1979), about 10% of the paper.\n",
      "   - Monolithic/non-modular.  For the specified sublanguage, everything specified.  Outside the bounds of the sublanguage, nothing specified.  How does the theory fit in with others?\n",
      "   - Exact opposite of the modern method -- researchers typically hold most aspects of the grammar constant (implicitly) while changing a few key points.  (*Portner and Partee intro*)\n",
      "\n",
      "**Summary:** In practice, the typical payoff for neither the reader nor the writer of a fragment exceeded the effort.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# A solution: digital fragments\n",
      "\n",
      "Von Eijck and Unger 2010: specify a fragment in digital form.\n",
      "\n",
      "* They use Haskell.  Type system of Haskell extremely well-suited to natural language semantics.\n",
      "* (Provocative statement) Interface, learning curve of Haskell not well suited to semanticists (or most people)?\n",
      "\n",
      "### Benefits of digital fragments (in principle)\n",
      "\n",
      "* Interactive.\n",
      "* Easy to distribute, adapt, modify.\n",
      "* Possibility of modularity.  (E.g. abstract a 'library' for compositional systems away from the analysis of a particular phenomenon.)\n",
      "* Bring closer together the CogSci idea of a 'computational model' to the project of natural language semantics.\n",
      "* Connections to computational semantics. (weak..)\n",
      "\n",
      "### What sorts of things might we want in a fragment / system for fragments?\n",
      "\n",
      "* Typed lambda calculus.\n",
      "* Logic / logical metalanguage.\n",
      "* Framework for semantic composition.  (Broad...)\n",
      "* Model theory? (x)\n",
      "* Interface with theorem provers? (x)\n",
      "\n",
      "IPython Lambda Notebook aims to provide these tools in a usable, interactive, format.\n",
      "\n",
      "* Choose Python, rather than Haskell/Java.  Easy learning curve, rapid prototyping, existence of IPython.\n",
      "\n",
      "**Layer 1**: interface using IPython Notebook.\n",
      "\n",
      "**Layer 2**: flexible typed metalanguage.\n",
      "\n",
      "**Layer 3**: composition system for metalanguage, building on layer 2."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Layer 1: an interface using IPython Notebook (Perez and Granger 2007) ##\n",
      "\n",
      " * Client-server system where an IPython \"kernel\" is running in the background.\n",
      " * Page broken down into cells in which can be entered python code, markdown code, raw text, other formats.\n",
      " * IPython: supports display of graphical representations of python objects.  (*Just-released IPython 2.0*: Javascript widgets!)\n",
      " * Most importantly, notebook uses the \"MathJax\" framework to enable it to render most math-mode latex.  Can have python objects automatically generate decent-looking formulas.  Can use latex math mode in documentation as well (e.g. $\\lambda x \\in D_e : \\mathit{CAT}(x)$)\n",
      "\n",
      "This all basically worked off-the-shelf.\n",
      "\n",
      "* Bulk of interface work so far: rendering code for logical and compositional representations.\n",
      "* Future: interactive widgets, packaging as an app.  Branding."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "meta.pmw_test1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "meta.pmw_test1._repr_latex_()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "&nbsp;\n",
      "\n",
      "## Part 2: a typed metalanguage ##"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Starting point (2012): a few implementations of things like predicate logic do exist, this is an intro AI exercise sometimes.  I started with the [AIMA python](http://code.google.com/p/aima-python/) _Expr_ class, based on the standard Russell and Norvig AI text.  But, had to scrap most of it.  Another starting point would have been `nltk.sem` (I was unaware of its existence at the time.) \n",
      "\n",
      "Preface cell with `%%lamb` to enter metalanguage formulas directly."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%lamb reset\n",
      "x = x_e # define x to have this type"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x.type"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%lamb\n",
      "test1 = L p_t : L x_e : P(x) & p # based on a Partee et al example\n",
      "test1b = L x_e : P(x) & Q(x)\n",
      "t2 = Q(x_e)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "These are now registered as variables in the python namespace and can be manipulated directly.  A typed lambda calculus is fully implemented with all that that entails.\n",
      "\n",
      "(Notice that beta reduction works properly, i.e. bound $x$ in the function is renamed.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test1(t2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test1(t2).reduce()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%lamb\n",
      "catf = L x_e: Cat(x)\n",
      "dogf = \u03bbx: Dog(x_e)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(catf(x)).type"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "catf.type"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Type checking of course is a part of all this:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test1(x) # function is type <t<et>> so will trigger a type mismatch.  This is a python exception so adds all sorts of extraneous stuff, but look to the bottom"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A more complex expression:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%lamb\n",
      "p2 = (Cat_<e,t>(x_e) & p_t) >> (Exists y: Dog_<e,t>(y_e))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "What is going on behind the scenes?  The objects manipulated are recursively structured python objects of class TypedExpr.\n",
      "\n",
      "Class _TypedExpr_: parent class for typed expressions.  Key subclasses:\n",
      "\n",
      "* BinaryOpExpr: parent class for things like conjunction.\n",
      "* TypedTerm: variables, constants of arbitrary type\n",
      "* BindingOp: operators that bind a single variable\n",
      "  * LFun: lambda expression\n",
      "\n",
      "Many straightforward expressions can be parsed.  Most expressions are created using a call to TypedExpr.factory, which is abbreviated as \"te\" in the following examples.  The `%%lamb` magic is calling this behind the scenes.\n",
      "\n",
      "Three ways of instantiating a variable `x` of type `e`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%lamb \n",
      "x = x_e # use cell magic"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = te(\"x_e\") # use factory function to parse string\n",
      "x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = meta.TypedTerm(\"x\", types.type_e) # use object constructer\n",
      "x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Various convenience python operators are overloaded, including functional calls.  Here is an example repeated from earlier in two forms:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%lamb\n",
      "p2 = (Cat_<e,t>(x_e) & p_t) >> (Exists y: Dog_<e,t>(y_e))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p2 = (te(\"Cat_<e,t>(x)\") & te(\"p_t\")) >> te(\"(Exists y: Dog_<e,t>(y_e))\")\n",
      "p2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's examine in detail what happens when a function and argument combine."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "catf = meta.LFun(types.type_e, te(\"Cat(x_e)\"), \"x\")\n",
      "catf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "catf(te(\"y_e\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Building a function-argument expression builds a complex, unreduced expression.  This can be explicitly reduced (note that the _reduce_all_ function applies this recursively):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "catf(te(\"y_e\")).reduce()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(catf(te(\"y_e\")).reduce()).derivation"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The metalanguage supports some basic type inference.  Not that this happens already on combination of a function and argument into an unreduced expression, not on beta-reduction."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%lamb ttest = L x_? : P_<?,t>(x) # type <?,t>\n",
      "%lamb tvar = y_t\n",
      "r = ttest(tvar)\n",
      "ltx_print(r, \"\", \"<b>Derivation:</b>\", r.derivation, r.type)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ltx_print(r.reduce(), \"\", \"<b>Derivation:</b>\", r.reduce().derivation)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Just to unpack this, (some) steps internal to a derivation are stored as a property on a TypedExpr:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r.reduce().derivation"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "&nbsp;\n",
      "\n",
      "## Part 3: composition systems for an object language ##\n",
      "\n",
      " * Focus on type-driven composition, current syntactic implementation fairly minimal\n",
      " * No shortage of ways to extend this.\n",
      "\n",
      "Key class(/mixin): _Composable_.  Some key subclasses:\n",
      "\n",
      " * _Item_: representation of a lexical item\n",
      " * _BinaryComposite_: result of composing any two _Composables_ using a single composition method.  Inherits from _nltk.Tree_!\n",
      " * _CompositionResult_: result of composing any two _Composables_ -- may represent multiple possible composition paths\n",
      "\n",
      "Key class: _CompositionSystem_.  Describes a set of composition operations."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# none of this is strictly necessary, the built-in library already provides effectively this system.\n",
      "pm = lang.BinaryCompositionOp(\"PM\", lang.pm_fun, commutative=False)\n",
      "fa = lang.BinaryCompositionOp(\"FA\", lang.fa_fun)\n",
      "pa = lang.BinaryCompositionOp(\"PA\", lang.pa_fun, allow_none=True)\n",
      "demo_hk_system = lang.CompositionSystem(name=\"demo system\", rules=[fa, pm, pa])\n",
      "lang.set_system(demo_hk_system)\n",
      "demo_hk_system"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%lamb\n",
      "||cat|| = L x_e: Cat(x)\n",
      "||gray|| = L x_e: Gray(x)\n",
      "||john|| = John_e\n",
      "||julius|| = Julius_e\n",
      "||inP|| = L x_e : L y_e : In(y)(x)\n",
      "||texas|| = Texas_e\n",
      "||isV|| = L p_<e,t> : p"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the purely type-driven mode, composition is triggered by using the '*' operator on a composable."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "inP * texas"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sentence1 = julius * (isV * (inP * texas))\n",
      "sentence1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sentence1.full_trace_latex()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I have temporarily disabled the fact that standard PM is symmetric/commutative (because of conjunction), to illustrated multiple composition paths:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gray * cat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gray * (cat * (inP * texas))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = lang.Item(\"a\", lang.isV.content) # identity function for copula as well\n",
      "isV * (a * (gray * cat * (inP * texas)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np = ((gray * cat) * (inP * texas))\n",
      "vp = (isV * (a * np))\n",
      "sentence2 = julius * vp\n",
      "sentence2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "julius * isV # will fail due to type mismatches"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sentence1.results[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sentence1.results[0].latex_step_tree()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sentence2.results[0].latex_step_tree()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "One of the infamous examples from Heim and Kratzer (names different):\n",
      "\n",
      " * Julius is a gray cat in Texas fond of John.\n",
      " \n",
      "First let's get rid of all the extra readings, to keep this simple."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "demo_hk_system.get_rule(\"PM\").commutative = True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fond = lang.Item(\"fond\", \"L x_e : L y_e : Fond(y)(x)\")\n",
      "ofP = lang.Item(\"of\", \"L x_e : x\")\n",
      "sentence3 = julius * (isV * (a * (((gray * cat) * (inP * texas)) * (fond * (ofP * john)))))\n",
      "sentence3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sentence3.latex_step_tree()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The _Composite_ class subclasses _nltk.Tree_, and so supports the things that class does.  E.g. []-based paths:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "parse_tree3 = sentence3.results[0]\n",
      "parse_tree3[0][1][1].latex_step_tree()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some basic support for traces."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "binder = lang.Item(\"23\", None)\n",
      "binder2 = lang.Item(\"5\", None)\n",
      "t = lang.Trace(23, types.type_e)\n",
      "t2 = lang.Trace(5)\n",
      "ltx_print(t, t2, binder)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "((t * gray))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b1 = (binder * (binder2 * (t * (lang.inP * t2))))\n",
      "b2 = (binder2 * (binder * (t * (lang.inP * t2))))\n",
      "ltx_print(b1, b2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b1.full_trace_latex()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "b1.results[0].latex_step_tree()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Composition in tree structures\n",
      "\n",
      "Current work: implementing tree-based computation, and top-down/deferred computation\n",
      "\n",
      "* using nltk Tree objects.\n",
      "* system for deferred / uncertain types -- basic inference over unknown types"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lang.set_system(lang.hk3_system)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%lamb\n",
      "||gray|| = L x_e : Gray_<e,t>(x)\n",
      "||cat|| = L x_e : Cat_<e,t>(x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t2 = Tree(\"S\", [\"NP\", \"VP\"])\n",
      "r2 = lang.hk3_system.compose(t2)\n",
      "r2.latex_step_tree() #._repr_latex_()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from lamb.tree_mini import Tree # hacked package to work with python 3\n",
      "t = Tree(\"NP\", [\"gray\", \"cat\"])\n",
      "t2 = lang.CompositionTree.tree_factory(t)\n",
      "t2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r = lang.hk3_system.compose(t2)\n",
      "r"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r.latex_step_tree()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r = lang.hk3_system.expand_all(t2)\n",
      "r"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r.latex_step_tree()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "&nbsp;\n",
      "\n",
      "## Some future projects, non-exhaustive ##\n",
      "\n",
      "* complete fragment of Heim and Kratzer\n",
      "* In general: more fragments!\n",
      "* extend fragment coverage.  Some interesting targets where interactivity would be useful to understanding:\n",
      "  * Continuations and quantification (Cf. van Eijck and Unger's Haskell implementation)\n",
      "  * Compositional hamblin semantics\n",
      "  * Compositional DRT\n",
      "* better inference over types.  (Standard algorithms from type-logical grammar?)\n",
      "* variables over types -- for type-flexible denotations.\n",
      "* underlying model theory.\n",
      "* various improvements to the graphics -- trees (d3?), interactive widgets (now doable in IPython 2.0), ...\n",
      "* full latex output (trees in tikz-qtree and so on).\n",
      "* better set theory mechanisms\n",
      "* presuppositions and some form of projection (Starting point, Heim and Kratzer)\n",
      "\n",
      "Longer term:\n",
      "\n",
      "* integration with SymPy (?)\n",
      "* release as an app\n",
      "* deeper integration with nltk (once nltk is compatible with python 3)\n",
      "* parsing that makes less use of python `eval`, and is generally less ad-hoc.\n",
      "  * this is an issue where in principle, a language like Haskell is a better choice than python.  But I think the usability / robustness of python and its libraries has the edge here overall, not to mention ipython notebook...\n",
      "* toy spatial language system\n",
      "* side-by-side comparison of e.g. multiple analyses of presupposition projection"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}