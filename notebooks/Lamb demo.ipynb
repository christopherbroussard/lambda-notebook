{
 "metadata": {
  "name": "",
  "signature": "sha256:66223ebce5a41234b1117edc3e41f5a18c0f8eadf0ea825519e05c0d5b9a96c0"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Lamb demo v. 0.9\n",
      "##Author: Kyle Rawlins\n",
      "\n",
      "Last updated April, 2014. History:\n",
      "\n",
      " * 0.5: first version\n",
      " * 0.6: updated to work with refactored class hierarchy (Apr 2013)\n",
      " * 0.6.1: small fixes to adapt to changes in various places (Sep 2013)\n",
      " * 0.7: various fixes to work with alpha release (Jan 2014)\n",
      " * 0.9: substantial updates, merge content from LSA poster (Apr 2014)\n",
      " \n",
      "To run through this demo, use shift-enter (runs and moves to next cell).  If you run things out of order, you may encounter problems (missing variables etc.)\n",
      "\n",
      "Note: this should always be saved in the repository without output."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from lamb.types import TypeMismatch, type_e, type_t, type_property\n",
      "from lamb.lang import te\n",
      "from lamb.utils import ltx_print\n",
      "from lamb.meta import TypedTerm, TypedExpr, LFun, CustomTerm\n",
      "#reload_lamb()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Just some basic configuration\n",
      "meta.constants_use_custom(False)\n",
      "lang.bracket_setting = lang.BRACKET_FANCY"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Two problems in formal semantics #\n",
      "\n",
      "1. Grammar fragments as in Montague Grammar: good idea in principle, hard to use in practice.\n",
      "\n",
      "  * A **fragment** is a *complete* formalization of *sublanguage* consisting of the *key relevant phenomena* for the problem at hand.  (Potential problem-points italicized.)\n",
      "\n",
      "2. Type-driven computation could be a lot easier to visualize and check.  (Q: could it be made too easy?)\n",
      "\n",
      "Solution: a system for developing interactive fragments: \"*IPython Lambda Notebook*\"\n",
      "\n",
      "* Creator can work interactively with analysis -- accelerate development, limit time spent on tedious details.\n",
      "* Reader can explore derivations in ways that are not typically possible in typical paper format.\n",
      "* Creator and reader can be certain that derivations work, verified by the system.\n",
      "\n",
      "Inspired by:\n",
      "\n",
      " * Von Eijck and Unger (2013): implementation of compositional semantics in Haskell.  No interface (beyond standard Haskell terminal); great if you like Haskell.  Introduced the idea of a fragment in digital form.\n",
      " * UPenn Lambda calculator (Champollion, Tauberer, and Romero 2007): teaching oriented.  (Now under development again.)\n",
      " * `nltk.sem`: implementation of the lambda calculus with a typed metalanguage, interface with theorem provers.  No interactive interface.\n",
      " * Jealousy of R studio, Matlab, Mathematica, etc.\n",
      "\n",
      "### The role of fragments ###\n",
      "\n",
      "What does *formal* mean in semantics?  What properties should a theory have?\n",
      "\n",
      " 1. Mathematically precise (lambda calculus, type theory, logic, model theory(?), ...)\n",
      " 2. Complete (covers \"all\" the relevant data).\n",
      " 3. Predictive (like any scientific theory).\n",
      " 4. Consistent, or at least compatible (with itself, analyses of other phenomena, some unifying conception of the grammar).\n",
      " \n",
      "The method of fragments provides a structure for meeting these criteria.\n",
      "\n",
      " * Paper with a fragment provides a working system.  (Probably.)\n",
      " * Explicit outer bound for empirical coverage.\n",
      " * Integration with a particular theory of grammar.  (To some extent.)\n",
      " * Explicit answer to many detailed questions not necessarily dealt with in the text.\n",
      " \n",
      "**Claim**: fragments are a method of replicability, similar to a computational modeller providing their model.\n",
      "\n",
      " * To be clear, a fragment is neither necessary nor sufficient for having a good theory / analysis / paper...\n",
      "\n",
      "Additional benefit: useful internal check for researcher.\n",
      "\n",
      ">\"...But I feel strongly that it is important to try to [work with fully explicit fragments] periodically, because otherwise it is extremely easy to think that you have a solution to a problem when in fact you don't.\" (Partee 1979, p. 41)\n",
      "\n",
      "### The challenges of fragments\n",
      "\n",
      "Part 1 of the above quote:\n",
      "\n",
      ">\"It can be very frustrating to try to specify frameworks and fragments explicitly; this project has not been entirely rewarding.  I would not recommend that one always work with the constraint of full explicitness.\" (Ibid.)\n",
      "\n",
      " * Fragments can be tedious and time-consuming to write (not to mention hard).\n",
      " * Fragments as traditionally written are in practice not easy for a reader to use.\n",
      " \n",
      "   - Dense/unapproachable.  With exactness can come a huge chunk of hard-to-digest formalism.  E.g. Partee (1979), about 10% of the paper.\n",
      "   - Monolithic/non-modular.  For the specified sublanguage, everything specified.  Outside the bounds of the sublanguage, nothing specified.  How does the theory fit in with others?\n",
      "   - Exact opposite of the modern method -- researchers typically hold most aspects of the grammar constant (implicitly) while changing a few key points.  (*Portner and Partee intro*)\n",
      "\n",
      "**Summary:** In practice, the typical payoff for neither the reader nor the writer of a fragment exceeded the effort.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# The solution\n",
      "\n",
      "Von Eijck and Unger 2010: specify a fragment in digital form.\n",
      "\n",
      "* They use Haskell.  Type system of Haskell extremely well-suited to natural language semantics.\n",
      "* (Provocative statement) Interface, learning curve of Haskell not well suited to semanticists (or most people)?\n",
      "\n",
      "### Benefits of digital fragments (in principle)\n",
      "\n",
      "* Interactive.\n",
      "* Easy to distribute, adapt, modify.\n",
      "* Possibility of modularity.  (E.g. abstract a 'library' for compositional systems away from the analysis of a particular phenomenon.)\n",
      "* Bring closer together the CogSci idea of a 'computational model' to the project of natural language semantics.\n",
      "* Connections to computational semantics. (weak..)\n",
      "\n",
      "### What sorts of things might we want in a fragment / system for fragments?\n",
      "\n",
      "* Typed lambda calculus.\n",
      "* Logic / logical metalanguage.\n",
      "* Framework for semantic composition.  (Broad...)\n",
      "* Model theory? (x)\n",
      "* Interface with theorem provers? (x)\n",
      "\n",
      "IPython Lambda Notebook aims to provide these tools in a usable, interactive, format.\n",
      "\n",
      "* Choose Python, rather than Haskell/Java.  Easy learning curve, rapid prototyping, existence of IPython.\n",
      "\n",
      "**Layer 1**: interface using IPython Notebook.\n",
      "\n",
      "**Layer 2**: flexible typed metalanguage.\n",
      "\n",
      "**Layer 3**: composition system for metalanguage, building on layer 2."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Layer 1: an interface using IPython Notebook (Perez and Granger 2007) ##\n",
      "\n",
      " * Client-server system where an IPython \"kernel\" is running in the background.\n",
      " * Page broken down into cells in which can be entered python code, markdown code, raw text, other formats.\n",
      " * IPython: supports display of graphical representations of python objects.  (*Just-released IPython 2.0*: Javascript widgets!)\n",
      " * Most importantly, notebook uses the \"MathJax\" framework to enable it to render most math-mode latex.\n",
      "\n",
      "This all basically worked off-the-shelf.\n",
      "\n",
      "* Bulk of interface work so far: rendering code for logical and compositional representations.\n",
      "* Future: interactive widgets, packaging as an app.  Branding."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "meta.pmw_test1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "meta.pmw_test1._repr_latex_()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "&nbsp;\n",
      "\n",
      "## Part 2: a typed metalanguage ##"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Starting point (2012): a few implementations of things like predicate logic do exist, this is an intro AI exercise sometimes.  I started with the [AIMA python](http://code.google.com/p/aima-python/) _Expr_ class, based on the standard Russell and Norvig AI text.  But, had to scrap most of it.  Another starting point would have been `nltk.sem` (I was unaware of its existence at the time.) \n",
      "\n",
      "Preface cell with `%%lamb` to enter metalanguage formulas directly."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%lamb reset\n",
      "test1 = L p_t : L x_e : P(x) & p\n",
      "test1b = L x_e : P(x) & Q(x)\n",
      "t2 = Q(x_e)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "These are now registered as variables in the python namespace and can be manipulated directly:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test1(t2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test1(t2).reduce()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "What is going on behind the scenes?  The objects manipulated are recursively structured python objects of class TypedExpr.\n",
      "\n",
      "Class _TypedExpr_: parent class for typed expressions.  Key subclasses:\n",
      "\n",
      "* BinaryOpExpr: parent class for things like conjunction.\n",
      "* TypedTerm: variables, constants of arbitrary type\n",
      "* BindingOp: operators that bind a single variable\n",
      "  * LFun: lambda expression\n",
      "\n",
      "Many straightforward expressions can be parsed.  Most expressions are created using a call to TypedExpr.factory, which is abbreviated as \"te\" in the following examples.  The `%%lamb` magic is calling this behind the scenes.\n",
      "\n",
      "Three ways of instantiating a variable `x` of type `e`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%lamb \n",
      "x = x_e # use cell magic"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = te(\"x_e\") # use factory function to parse string\n",
      "x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = meta.TypedTerm(\"x\", types.type_e) # use object constructer\n",
      "x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Misc notes: There is some convenience type guessing to make expressions shorter.  That is, '_Cat_' in the next cell does not have an explicit type and so the initial guess is t, but it realizes that the argument is type _e_ and so adjusts it up to _<e,t>_.  This form of type inference is not very general and really intended for convenience in writing expresssions like this.  (There are examples of the more general type inference system below.)\n",
      "\n",
      "To turn off notices about this form of type guessing, you can call _meta.logger.setLevel(meta.logging.WARNING)_ to raise the logging level, and _meta.logger.setLevel(meta.logging.INFO)_ to re-enable."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#meta.logger.setLevel(meta.logging.WARNING)\n",
      "%lamb p1 = Cat(x_e)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x1 = te(\"L x_e: Cat(x)\")\n",
      "x2 = te(\"\u03bbx: Dog(x_e)\")\n",
      "\n",
      "ltx_print(x1, x2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# natural language-ish metalanguage, following Heim and Kratzer.\n",
      "# note that I basically recommend against using this.\n",
      "cat_term = meta.CustomTerm(\"Cat\", typ=types.type_property)\n",
      "var = te(\"x_e\")\n",
      "cat_term(var)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(cat_term(var)).type"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cat_term.type"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Various convenience python operators are overloaded, including functional calls:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(cat_term(var) & te(\"p_t\")) >> te(\"q_t\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This all works in the metalanguage parser:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%lamb\n",
      "p2 = (Cat_<e,t>(x_e) & p_t) >> q_t"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's examine in detail what happens when a function and argument combine."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cat_fun = meta.LFun(types.type_e, cat_term(var), \"x\")\n",
      "cat_fun"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cat_fun(te(\"y_e\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Building a function-argument expression builds a complex, unreduced expression.  This can be explicitly reduced (note that the _reduce_all_ function applies this recursively):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cat_fun(te(\"y_e\")).reduce()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test1(t2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test1(t2).reduce()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice that the variable _x_ is renamed to _x1_ to avoid conflict with the free _x_ in _t2_."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test1(x) # function is type <t<et>> so will trigger a type mismatch"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The metalanguage supports some basic type inference.  Not that this happens already on combination of a function and argument into an unreduced expression, not on beta-reduction."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%lamb ttest = L x_? : P_<?,t>(x) # type <?,t>\n",
      "%lamb tvar = y_t\n",
      "r = ttest(tvar)\n",
      "ltx_print(r, \"\", \"<b>Derivation:</b>\", r.derivation, r.type)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ltx_print(r.reduce(), \"\", \"<b>Derivation:</b>\", r.reduce().derivation)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Just to unpack this, (some) steps internal to a derivation are stored as a property on a TypedExpr:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r.reduce().derivation"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "&nbsp;\n",
      "\n",
      "## Part 3: composition systems for an object language ##\n",
      "\n",
      " * Focus on type-driven composition, current syntactic implementation fairly minimal\n",
      " * No shortage of ways to extend this.\n",
      "\n",
      "Key class(/mixin): _Composable_.  Some key subclasses:\n",
      "\n",
      " * _Item_: representation of a lexical item\n",
      " * _BinaryComposite_: result of composing any two _Composables_ using a single composition method.  Inherits from _nltk.Tree_!\n",
      " * _CompositionResult_: result of composing any two _Composables_ -- may represent multiple possible composition paths\n",
      "\n",
      "Key class: _CompositionSystem_.  Describes a set of composition operations."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def demo_fa_fun(fun, arg, assignment=None):\n",
      "    if (not fun.type.functional()) or fun.type.left != arg.type:\n",
      "        raise TypeMismatch(fun, arg, \"Function Application\")\n",
      "    return lang.BinaryComposite(fun, arg, \n",
      "                (fun.content.under_assignment(assignment)(arg.content.under_assignment(assignment))).reduce())\n",
      "\n",
      "# implement PM via the following combinator:\n",
      "pm_op = lang.te(\"L f_<e,t> : L g_<e,t> : L x_e : f(x) & g(x)\")\n",
      "\n",
      "def demo_pm_fun(fun1, fun2, assignment=None):\n",
      "    \"\"\"H&K predicate modification -- restricted to type <et>.\"\"\"\n",
      "    ts = meta.get_type_system()\n",
      "    if not (ts.eq_check(fun1.type, types.type_property) and \n",
      "            ts.eq_check(fun2.type, types.type_property)):\n",
      "        raise TypeMismatch(fun1, fun2, \"Predicate Modification\")\n",
      "    varname = fun1.content.varname\n",
      "    c1 = fun1.content.under_assignment(assignment)\n",
      "    c2 = fun2.content.under_assignment(assignment)\n",
      "    result = pm_op.apply(c1).apply(c2).reduce_all()\n",
      "    return lang.BinaryComposite(fun1, fun2, result)\n",
      "\n",
      "pm = lang.BinaryCompositionOp(\"PM\", demo_pm_fun, commutative=False)\n",
      "fa = lang.BinaryCompositionOp(\"FA\", demo_fa_fun)\n",
      "pa = lang.BinaryCompositionOp(\"PA\", lang.pa_fun, allow_none=True)\n",
      "demo_hk_system = lang.CompositionSystem(rules=[fa, pm, pa], basictypes={type_e, type_t})\n",
      "lang.set_system(demo_hk_system)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#meta.constants_use_custom(True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%lamb\n",
      "||cat|| = L x_e: Cat(x)\n",
      "||gray|| = L x_e: Gray(x)\n",
      "||john|| = John_e\n",
      "||julius|| = Julius_e\n",
      "||inP|| = L x_e : L y_e : In(y)(x)\n",
      "||texas|| = Texas_e\n",
      "||isV|| = L p_<e,t> : p"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# if you want to use H&K style metalanguage, there are various hooks for doing this.\n",
      "gray.content.args[0].op.custom = \"is\"\n",
      "inP.content.args[0].args[0].op.op.custom = \"is\"\n",
      "ltx_print(gray, inP)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the purely type-driven mode, composition is triggered by using the '*' operator on a composable."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "inP * texas"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sentence1 = julius * (isV * (inP * texas))\n",
      "sentence1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sentence1.full_trace_latex()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I have temporarily disabled the fact that standard PM is symmetric, to illustrated multiple composition paths:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gray * cat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gray * (cat * (inP * texas))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = lang.Item(\"a\", lang.isV.content) # identity function for copula as well\n",
      "isV * (a * (gray * cat * (inP * texas)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np = ((gray * cat) * (inP * texas))\n",
      "vp = (isV * (a * np))\n",
      "sentence2 = julius * vp\n",
      "sentence2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "julius * isV # will fail due to type mismatches"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "sentence2.full_trace_latex()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sentence1.results[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sentence1.results[0].latex_step_tree()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sentence2.results[0].latex_step_tree()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "One of the infamous examples from Heim and Kratzer (names different):\n",
      "\n",
      " * Julius is a gray cat in Texas fond of John."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fond = lang.Item(\"fond\", \"L x_e : L y_e : Fond(y)(x)\")\n",
      "ofP = lang.Item(\"of\", \"L x_e : x\")\n",
      "sentence3 = julius * (lang.isV * (a * (np * (fond * (ofP * lang.john)))))\n",
      "sentence3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sentence3.results[0].latex_step_tree()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The _Composite_ class subclasses _nltk.Tree_, and so supports the things that class does.  E.g. []-based paths:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "parse_tree3 = sentence3.results[0]\n",
      "parse_tree3[0][1][1].latex_step_tree()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some basic support for traces."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "binder = lang.Item(\"23\", None)\n",
      "binder2 = lang.Item(\"5\", None)\n",
      "t = lang.Trace(23, types.type_e)\n",
      "t2 = lang.Trace(5)\n",
      "ltx_print(t, t2, binder)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "((t * gray))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b1 = (binder * (binder2 * (t * (lang.inP * t2))))\n",
      "b2 = (binder2 * (binder * (t * (lang.inP * t2))))\n",
      "ltx_print(b1, b2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b1.full_trace_latex()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "b1.results[0].latex_step_tree()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Composition in tree structures\n",
      "\n",
      "Current work: implementing tree-based computation, and top-down/deferred computation\n",
      "\n",
      "* using nltk Tree objects.\n",
      "* system for deferred / uncertain types -- basic inference over unknown types"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t2 = Tree(\"S\", [\"NP\", \"VP\"])\n",
      "r2 = lang.hk3_system.compose(t2)\n",
      "r2.latex_step_tree() #._repr_latex_()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from lamb.tree_mini import Tree # hacked package to work with python 3\n",
      "t = Tree(\"S\", [cat, \"VP\"])  # this is a tree with a missing VP.  Exploit the fact that Composites are trees and nodes can be Items in lamb.\n",
      "#local_tree = lang.tfa_l.build_local(t)\n",
      "#local_tree # need to implement ipython output routines for nltk.Tree.\n",
      "#lang.hk3_system.compose(t)\n",
      "t2 = lang.CompositionTree.tree_factory(t)\n",
      "t2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r = lang.hk3_system.compose(t)\n",
      "r"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r.latex_step_tree()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "&nbsp;\n",
      "\n",
      "## Some future projects, non-exhaustive ##\n",
      "\n",
      "* complete fragment of Heim and Kratzer\n",
      "* In general: more fragments!\n",
      "* extend fragment coverage.  Some interesting targets where interactivity would be useful to understanding:\n",
      "  * Continuations and quantification (Cf. van Eijck and Unger's Haskell implementation)\n",
      "  * Compositional hamblin semantics\n",
      "  * Compositional DRT\n",
      "* better inference over types.  (Standard algorithms from type-logical grammar?)\n",
      "* variables over types -- for type-flexible denotations.\n",
      "* underlying model theory.\n",
      "* various improvements to the graphics -- trees (d3?), interactive widgets (now doable in IPython 2.0), ...\n",
      "* full latex output (trees in tikz-qtree and so on).\n",
      "* better set theory mechanisms\n",
      "* presuppositions and some form of projection (Starting point, Heim and Kratzer)\n",
      "\n",
      "Longer term:\n",
      "\n",
      "* integration with SymPy (?)\n",
      "* release as an app\n",
      "* deeper integration with nltk (once nltk is compatible with python 3)\n",
      "* parsing that makes less use of python `eval`, and is generally less ad-hoc.\n",
      "  * this is an issue where in principle, a language like Haskell is a better choice than python.  But I think the usability / robustness of python and its libraries has the edge here overall, not to mention ipython notebook...\n",
      "* toy spatial language system\n",
      "* side-by-side comparison of e.g. multiple analyses of presupposition projection"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}