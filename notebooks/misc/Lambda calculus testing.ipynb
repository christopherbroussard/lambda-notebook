{
 "metadata": {
  "name": "",
  "signature": "sha256:3ccc6c87d336b910bfe916bdbf96a6ea7cfc1964ac0da489b344a89143376c44"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Lambda calculus testing\n",
      "## Author: Kyle Rawlins\n",
      "\n",
      "This notebook contains various examples that can be useful for testing that beta reduction is working correctly (among other things).  They also may be helpful for understanding how variable renaming works in the lambda notebook."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lamb.reload_all()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = lang.te(\"x_e\")\n",
      "y = lang.te(\"y_e\")\n",
      "z = lang.te(\"z_e\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test2 = lang.te(\"L y_e : L x_e : y_e\")\n",
      "test2(x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "latex": [
        "$[\\lambda{} y_{e} \\: . \\: \\lambda{} x_{e} \\: . \\: {y}_{e}]({x}_{e})$"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "((\u03bb y_e: (\u03bb x_e: y_e)))(x_e)"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test2.apply(x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "latex": [
        "$\\lambda{} x1_{e} \\: . \\: {x}_{e}$"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "(\u03bb x1_e: x_e)"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "meta.alpha_convert_new(test2, {\"y\"})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "latex": [
        "$\\lambda{} y1_{e} \\: . \\: \\lambda{} x_{e} \\: . \\: {y1}_{e}$"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "(\u03bb y_e: (\u03bb x_e: y1_e))"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test3 = lang.te(\"L y_e : L y1_e : P(y_e) & q_t\")\n",
      "test3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO (meta): Coerced guessed type t for 'P_t' into <e,t>, to match argument 'y_e'\n"
       ]
      },
      {
       "latex": [
        "$\\lambda{} y_{e} \\: . \\: \\lambda{} y1_{e} \\: . \\: ({P}({y}_{e}) \\wedge{} {q}_{t})$"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "(\u03bb y_e: (\u03bb y1_e: (P_<e,t>(y_e) & q_t)))"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "meta.alpha_convert_new(test3, {\"x\", \"y\", \"q\"})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "latex": [
        "$\\lambda{} y2_{e} \\: . \\: \\lambda{} y1_{e} \\: . \\: ({P}({y2}_{e}) \\wedge{} {q}_{t})$"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "(\u03bb y_e: (\u03bb y1_e: (P_<e,t>(y2_e) & q_t)))"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "meta.pmw_test1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "latex": [
        "$\\lambda{} p_{t} \\: . \\: \\lambda{} x_{e} \\: . \\: ({P}({x}_{e}) \\wedge{} {p}_{t})$"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "(\u03bb p_t: (\u03bb x_e: (P_<e,t>(x_e) & p_t)))"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "meta.pmw_test1b"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "latex": [
        "$\\lambda{} x_{e} \\: . \\: ({P}({x}_{e}) \\wedge{} {Q}({x}_{e}))$"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "(\u03bb x_e: (P_<e,t>(x_e) & Q_<e,t>(x_e)))"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "meta.pmw_test1(meta.t2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "latex": [
        "$[\\lambda{} p_{t} \\: . \\: \\lambda{} x_{e} \\: . \\: ({P}({x}_{e}) \\wedge{} {p}_{t})]({Q}({x}_{e}))$"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 33,
       "text": [
        "((\u03bb p_t: (\u03bb x_e: (P_<e,t>(x_e) & p_t))))(Q_<e,t>(x_e))"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "meta.pmw_test1(meta.t2).reduce().derivation"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "latex": [
        "<table><tr style=\"border-bottom:1px solid #848482\"><td style=\"padding-right:5px\"> 1. </td><td style=\"padding-right:5px\">$[\\lambda{} p_{t} \\: . \\: \\lambda{} x_{e} \\: . \\: ({P}({x}_{e}) \\wedge{} {p}_{t})]({Q}({x}_{e}))$</td><td style=\"padding-left:10px;border-left:1px solid #848482\"></td></tr><tr style=\"border-bottom:1px solid #848482\"><td style=\"padding-right:5px\"> 2. </td><td style=\"padding-right:5px\">$\\lambda{} x1_{e} \\: . \\: ({P}({x1}_{e}) \\wedge{} {Q}({x}_{e}))$</td><td style=\"padding-left:10px;border-left:1px solid #848482\"><span style=\"color:blue\">F-A reduction</span></td></tr></table>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "<lamb.meta.Derivation at 0x101f69b90>"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test4 = lang.te(\"L x_e : x\")\n",
      "test4"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "latex": [
        "$\\lambda{} x_{e} \\: . \\: {x}_{e}$"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "(\u03bb x_e: x_e)"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test4(x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "latex": [
        "$[\\lambda{} x_{e} \\: . \\: {x}_{e}]({x}_{e})$"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "((\u03bb x_e: x_e))(x_e)"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r = meta.pmw_test1(meta.t2).reduce()\n",
      "r.derivation"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "latex": [
        "<table><tr style=\"border-bottom:1px solid #848482\"><td style=\"padding-right:5px\"> 1. </td><td style=\"padding-right:5px\">$[\\lambda{} p_{t} \\: . \\: \\lambda{} x_{e} \\: . \\: ({P}({x}_{e}) \\wedge{} {p}_{t})]({Q}({x}_{e}))$</td><td style=\"padding-left:10px;border-left:1px solid #848482\"></td></tr><tr style=\"border-bottom:1px solid #848482\"><td style=\"padding-right:5px\"> 2. </td><td style=\"padding-right:5px\">$\\lambda{} x1_{e} \\: . \\: ({P}({x1}_{e}) \\wedge{} {Q}({x}_{e}))$</td><td style=\"padding-left:10px;border-left:1px solid #848482\"><span style=\"color:blue\">F-A reduction</span></td></tr></table>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 37,
       "text": [
        "<lamb.meta.Derivation at 0x101f6d150>"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reload_lamb()\n",
      "meta.TypedExpr.try_parse_op_expr(\"lambda x_e:P_<e,t>(x)\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "latex": [
        "$\\lambda{} x_{e} \\: . \\: {P}({x}_{e})$"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 38,
       "text": [
        "(\u03bb x_e: P_<e,t>(x_e))"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lang.te(\"L y_e : Exists x_e : P(x_e)(y)\")(lang.te(\"x_e\")).reduce().derivation"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO (meta): Coerced guessed type t for 'P_t' into <e,t>, to match argument 'x_e'\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO (meta): Coerced guessed type t for 'P_<e,t>(x_e)' into <e,t>, to match argument 'y_e'\n"
       ]
      },
      {
       "latex": [
        "<table><tr style=\"border-bottom:1px solid #848482\"><td style=\"padding-right:5px\"> 1. </td><td style=\"padding-right:5px\">$[\\lambda{} y_{e} \\: . \\: \\exists{} x_{e} \\: . \\: {P}_{\\langle{}e,\\langle{}e,t\\rangle{}\\rangle{}}({x}_{e})({y}_{e})]({x}_{e})$</td><td style=\"padding-left:10px;border-left:1px solid #848482\"></td></tr><tr style=\"border-bottom:1px solid #848482\"><td style=\"padding-right:5px\"> 2. </td><td style=\"padding-right:5px\">$\\exists{} x1_{e} \\: . \\: {P}_{\\langle{}e,\\langle{}e,t\\rangle{}\\rangle{}}({x1}_{e})({x}_{e})$</td><td style=\"padding-left:10px;border-left:1px solid #848482\"><span style=\"color:blue\">F-A reduction</span></td></tr></table>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 39,
       "text": [
        "<lamb.meta.Derivation at 0x106169850>"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%lamb test = (lambda w_n  : Exists q_<n,t> : q(w))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "latex": [
        "${test}_{\\langle{}n,t\\rangle{}}\\:=\\:\\lambda{} w_{n} \\: . \\: \\exists{} q_{\\langle{}n,t\\rangle{}} \\: . \\: {q}_{\\langle{}n,t\\rangle{}}({w}_{n})$"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 40,
       "text": [
        "${test}_{\\langle{}n,t\\rangle{}}\\:=\\:\\lambda{} w_{n} \\: . \\: \\exists{} q_{\\langle{}n,t\\rangle{}} \\: . \\: {q}_{\\langle{}n,t\\rangle{}}({w}_{n})$"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%lamb test = (Lambda w_n  : w)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "latex": [
        "${test}_{\\langle{}n,n\\rangle{}}\\:=\\:\\lambda{} w_{n} \\: . \\: {w}_{n}$"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 44,
       "text": [
        "${test}_{\\langle{}n,n\\rangle{}}\\:=\\:\\lambda{} w_{n} \\: . \\: {w}_{n}$"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}