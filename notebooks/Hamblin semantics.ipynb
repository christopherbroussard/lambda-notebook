{
 "metadata": {
  "name": "",
  "signature": "sha256:a1840c82e824c1ef70a2833e52303afe4d70b97d8ba20cf6ab7046714a9eba78"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Hamblin semantics\n",
      "## Author: Kyle Rawlins\n",
      "\n",
      "This is an implementation of Hamblin semantics.  It is currently quite incomplete."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reload_lamb()\n",
      "%lambctl reset"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type_e = types.type_e\n",
      "type_t = types.type_t\n",
      "type_n = types.type_n\n",
      "type_s = types.OntoType(\"s\", types.SimpleInfiniteSet(\"c\"))\n",
      "intensional_types = types.UnderTypeSystem(atomics={type_e, type_t, type_n, type_s, types.undetermined_type}, nonatomics={types.FunType, types.TupleType, types.SetType, types.UndeterminedType})\n",
      "meta.set_type_system(intensional_types)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The first thing to do is to 'hamblinize' the lexicon.  This amounts to converting ordinary meanings to singleton sets with there contents.\n",
      "\n",
      "There are a number of options for how to implement this in a typed lambda calculus.  Here, we will exploit the fact that the Lambda Notebook has a type for sets.  If $\\alpha$ is a type, then $\\{\\alpha\\}$ is the type of sets containing elements of type $\\alpha$.  This is someone backwards from how most textbooks define types vs. sets, and more consistent with a programmer's way of thinking about the issue.\n",
      "\n",
      "The next bit of code defines a special operation `hamblinize` to simplify the process a bit; it can be safely ignored."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def hamblinize_te(te):\n",
      "    \"\"\"Hamblinize a single lexical item.  Do so by building a singleton set out of it.\"\"\"\n",
      "    if meta.ts_compatible(te.type, meta.tp(\"{?}\")): #isinstance(item.type, types.SetType):\n",
      "        # assume this item is already hamblinized\n",
      "        return te\n",
      "    elif meta.ts_compatible(te.type, meta.tp(\"<{?},?>\")): #item.type.functional() and isinstance(item.type.left, types.SetType):\n",
      "        # heuristic: if function whose domain is a set of some sort, assume that this is a Hamblin operator.\n",
      "        # may miss cases.  Better to just run this on content items...\n",
      "        return te\n",
      "    # wrap the content of the lexical item as a singleton set.\n",
      "    return meta.ListedSet([te])    \n",
      "\n",
      "#continuize_lex(cat1.content)\n",
      "lamb.parsing.eq_transforms[\"hamblin\"] = hamblinize_te"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's see this in operation:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%lamb\n",
      "||cat|| =<hamblin> L x_e : L w_s : Cat(w,x)\n",
      "||gray|| =<hamblin> L x_e : L w_s : Gray(w,x)\n",
      "||john|| =<hamblin> J_e\n",
      "x =<hamblin> L y_e : y\n",
      "||test|| = L x_e : Test(x) # don't hamblinize this"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next, we need to add a way of composing entries *pointwise*.  The following code implements the most general case of Pointwise FA.\n",
      "\n",
      "In the long run, one would want to automatically simplify these expressions; this is easy to do by hand, but it is a hard problem in the general case, so things are left mostly unsimplified."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pfa_combinator(funtype, argtype):\n",
      "    return te(\"L f_{%s} : L a_{%s} : Set x_%s : Exists f1_%s : (Exists a1_%s : (f1 << f & a1 << a) & x <=> f1(a1))\" % (repr(funtype), repr(argtype), repr(funtype.right), repr(funtype), repr(argtype)))\n",
      "\n",
      "pfa_combinator(tp(\"<e,<s,t>>\"), types.type_e)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pfa_worstcase(fun, arg):\n",
      "    ts = meta.get_type_system()\n",
      "    if not (isinstance(fun.type, types.SetType) \n",
      "            and isinstance(arg.type, types.SetType)):\n",
      "        raise types.TypeMismatch(fun, arg, \"Pointwise Function Application\")\n",
      "    if not (ts.fun_arg_check_types_bool(fun.type.content_type, arg.type.content_type)):\n",
      "        raise types.TypeMismatch(fun, arg, \"Pointwise Function Application\")\n",
      "    return pfa_combinator(fun.type.content_type, arg.type.content_type)(fun)(arg)\n",
      "\n",
      "system = lang.td_system.copy()\n",
      "system.add_rule(lang.binary_factory(pfa_worstcase, \"PFA\"))\n",
      "lang.set_system(system)\n",
      "system"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "john * cat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Instead of automatically simplifying things, I'll exploit the fact that sets are represented differently (as a list) if they are finite, so we can special-case PFA for ListedSets, and fall back on the combinator for the general case.\n",
      "\n",
      "Note that some limited reduction does occur with the $\\in$ operator; $x \\in \\{y \\:|\\: \\phi\\}$ gets converted to $(\\lambda y : \\phi)(x)$ and reduced, illustrated in the next cell."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r = te(\"x_e << (Set y_e : Test_<e,t>(y))\")\n",
      "r.reduce_all().derivation"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pfa_listed(fun, arg):\n",
      "    result = list()\n",
      "    for felem in fun.args:\n",
      "        for aelem in arg.args:\n",
      "            result.append(felem(aelem))\n",
      "    return meta.ListedSet(result)\n",
      "\n",
      "def pfa_general(fun, arg):\n",
      "    ts = meta.get_type_system()\n",
      "    if not (isinstance(fun.type, types.SetType) \n",
      "            and isinstance(arg.type, types.SetType)):\n",
      "        raise types.TypeMismatch(fun, arg, \"Pointwise Function Application\")\n",
      "    if not (ts.fun_arg_check_types_bool(fun.type.content_type, arg.type.content_type)):\n",
      "        raise types.TypeMismatch(fun, arg, \"Pointwise Function Application\")\n",
      "    if isinstance(fun, meta.ListedSet) and isinstance(arg, meta.ListedSet):\n",
      "        return pfa_listed(fun, arg)\n",
      "    else:\n",
      "        return pfa_combinator(fun.type.content_type, arg.type.content_type)(fun)(arg)\n",
      "    \n",
      "system = lang.td_system.copy()\n",
      "system.add_rule(lang.binary_factory(pfa_general, \"PFA\", reduce=True))\n",
      "lang.set_system(system)\n",
      "system"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "john * cat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%lamb\n",
      "||who|| = Set x_e : Human(x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(cat * who).tree()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%lamb\n",
      "||saw|| =<hamblin> L x_e : L y_e : L w_s : Saw(w,y,x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "john * (saw * who)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "who * (saw * john)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%lamb\n",
      "||HExists|| = L p_{<s,t>} : {(Lambda w_s  : Exists q_<s,t> : q(w) & (q << p))}\n",
      "||HForall|| = L p_{<s,t>} : {(Lambda w_s  : Forall q_<s,t> : q(w) >> (q << p))}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "HExists * (who * (saw * john))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The above formulas are somewhat involved, so it is slightly more convenient to simply define a toy example with a finite set of individuals:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%lamb\n",
      "||who2|| = {John_e, Mary_e, Sue_e}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "HExists * (who2 * (saw * john))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "HExists * (john * (saw * who2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Appendix: another technique for Hamblinization\n",
      "\n",
      "Another way of Hamblinizing a lexicon would be to write extra magics for converting whole lexicons at once.  Here's a sketch of how to do this."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "raise Exception(\"Prevent run-all from working\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def hamblinize_item(item):\n",
      "    \"\"\"Hamblinize a single lexical item.  Do so by building a singleton set out of it.\"\"\"\n",
      "    if meta.ts_compatible(item.type, meta.tp(\"{?}\")): #isinstance(item.type, types.SetType):\n",
      "        # assume this item is already hamblinized\n",
      "        return item\n",
      "    elif meta.ts_compatible(item.type, meta.tp(\"<{?},?>\")): #item.type.functional() and isinstance(item.type.left, types.SetType):\n",
      "        # heuristic: if function whose domain is a set of some sort, assume that this is a Hamblin operator.\n",
      "        # may miss cases.  Better to just run this on content items...\n",
      "        return item\n",
      "    new_i = item.copy()\n",
      "    # wrap the content of the lexical item as a singleton set.\n",
      "    new_i.content = meta.ListedSet([item.content])\n",
      "    return new_i\n",
      "\n",
      "# in the following two magics, variables that are not lexical items are ignored.  To change this, modify the else case above.\n",
      "def h_magic(self, accum):\n",
      "    \"\"\"Hamblinize the accumulated definitions from a single cell, as a post-processing step\"\"\"\n",
      "    new_accum = lamb.magics.process_items(hamblinize_item, accum)[0]\n",
      "    for k in new_accum.keys():\n",
      "        self.env[k] = new_accum[k]\n",
      "    return new_accum\n",
      "\n",
      "def h_magic_env(self):\n",
      "    \"\"\"Hamblinize the entire env\"\"\"\n",
      "    self.env = lamb.magics.process_items(hamblinize_item, self.env)[0] # hamblinize every variable\n",
      "    self.shell.push(self.env) # export the new variables to the interactive shell\n",
      "    return parsing.latex_output(self.env, self.env)\n",
      "\n",
      "lamb.magics.LambMagics.specials_post[\"hamblinize\"] = h_magic\n",
      "lamb.magics.LambMagics.specials[\"hamblinize_all\"] = h_magic_env"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%lamb hamblinize\n",
      "||cat|| = L x_e : L w_s : Cat(w,x)\n",
      "||gray|| = L x_e : L w_s : Gray(w,x)\n",
      "||john|| = J_e\n",
      "x = L y_e : y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%lamb\n",
      "||test|| = L x_e : Test(x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%lambctl hamblinize_all"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}