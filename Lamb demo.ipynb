{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Lamb demo v. 0.7\n",
      "##Author: Kyle Rawlins\n",
      "\n",
      "Last updated Jan 13, 2014. History:\n",
      "\n",
      " * 0.5: first version\n",
      " * 0.6: updated to work with refactored class hierarchy (Apr 2013)\n",
      " * 0.6.1: small fixes to adapt to changes in various places (Sep 2013)\n",
      " * 0.7: various fixes to work with alpha release\n",
      " \n",
      "To run through this demo, use shift-enter (runs and moves to next cell)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# load some classes and then put some convenience names into the local namespace\n",
      "import lamb\n",
      "from lamb import *\n",
      "from lamb.tree_mini import Tree\n",
      "from lamb.utils import *\n",
      "import imp\n",
      "#imp.reload(lamb)\n",
      "#imp.reload(lang)\n",
      "from lamb.types import TypeMismatch, type_e, type_t, type_property\n",
      "from lamb.lang import te\n",
      "from lamb.utils import ltx_print\n",
      "from lamb.meta import TypedTerm, TypedExpr, LFun, CustomTerm\n",
      "def reload_all():\n",
      "    imp.reload(lamb.utils)\n",
      "    imp.reload(lamb.types)\n",
      "    imp.reload(lamb.meta)\n",
      "    imp.reload(lamb.lang)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# it will become clear what this does later\n",
      "lamb.meta.constants_use_custom(False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Two problems in formal semantics #\n",
      "\n",
      "1. Grammar fragments as in Montague Grammar: good idea in principle, hard to use in practice.\n",
      "2. Type-driven computation could be a lot easier to visualize and check.  (Q: could it be made too easy?)\n",
      "\n",
      "Solution: a system for developing interactive fragments: \"*lamb*\"\n",
      "\n",
      "* Creator can work interactively with analysis -- accelerate development, limit time spent on tedious details.\n",
      "* Reader can explore derivations in ways that are not typically possible in typical paper format.\n",
      "* Creator and reader can be certain that derivations work, verified by the system.\n",
      "\n",
      "Inspired (to some degree) by interactive/automatic proof assistants such as _agda_ and _coq_.  In the python world, _SymPy_ provides some of this functionality but has very little overlap with what is needed for formal semantics.\n",
      "\n",
      "### Grammar fragments: pros and cons ###\n",
      "\n",
      "Pros:\n",
      "\n",
      "* Require writer to set out a complete set of assumptions.\n",
      "* What are the stipulations?  (E.g. Stump's diss: turns out that distinction between weak and strong is syntactic.)\n",
      "  * No need to read between the lines / fill in assumptions.  Even a textbook like Heim and Kratzer doesn't always achieve this degree of detail.  Ex: Kratzer and Shimoyama's Alternative Semantics.\n",
      "* Serve as a kind of certificate of validity.\n",
      "* Can allow text of paper to focus on ideas, not as much on example derivations etc.  (Ex: Elbourne's book.)\n",
      "\n",
      "Cons:\n",
      "\n",
      "* Difficult to impossible to use, for readers who are not deeply embedded in a very particular set of assumptions.\n",
      "  * Error in a fragment may remain undetected?  Note, I don't have any cases of this in mind and hesitate to really take on this task.\n",
      "* Historically, tied to a very different view of syntax.  (Not everyone would take this as a con...)\n",
      "* More generally: not modular.  Typically, cannot easily take pieces without a _tremendous_ amount of work.\n",
      "\n",
      "Some solutions exist, but are not widely known / adopted, and are ad-hoc to varying degrees.\n",
      "\n",
      "* John Hale's LF code for implementing QR in ML.  (Where I first encountered the idea.)\n",
      "* UPenn teaching tool for compositional semantics (not designed for working semanticist, not currently in development)\n",
      "* Book: van Eijck and Unger 2010, *Computational semantics with functional programming*\n",
      "  * Implementation of type-driven composition + some syntax in Haskell.\n",
      "  * Use Haskell itself for most of the inference.  (This is what Haskell is good for after all.)  But, Haskell, is not widely known / used.\n",
      "  * Centered more around understanding the programming task / implementation, than producing the kind of tool I'm aiming at.\n",
      "  * Possible seminar in spring, if I can get enough people interested?\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Part 1: an interface using ipython notebook ##\n",
      "\n",
      " * Client-server system where an ipython \"kernel\" is running in the background.\n",
      " * Page broken down into cells in which can be entered python code, markdown code, or raw text\n",
      " * ipython provides frameworks for graphical representations of python objects in this kind of setup\n",
      " * most importantly, notebook uses the \"MathJax\" framework to enable it to render most math-mode latex\n",
      "\n",
      "This all basically worked off-the-shelf, all I had to do was write the latex/html code that gets handed off to mathjax!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "meta.pmw_test1._repr_latex_()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "meta.pmw_test1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "&nbsp;\n",
      "\n",
      "## Part 2: a typed metalanguage ##"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Starting point: a few implementations of things like predicate logic do exist, this is an intro AI exercise sometimes.  I started with the [AIMA python](http://code.google.com/p/aima-python/) _Expr_ class, based on the standard Russell and Norvig AI text.  But, had to scrap most of it.\n",
      "\n",
      "Class _TypedExpr_: parent class for typed expressions\n",
      "\n",
      "* TypedTerm: variables, constants of arbitrary type\n",
      "* BindingOp: operators that bind a single variable\n",
      "  * LFun: lambda expression\n",
      "\n",
      "Many straightforward expressions can be parsed.  Most expressions are created using a call to TypedExpr.factory, which is abbreviate as \"te\" in the following examples."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "te(\"x_e\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "meta.TypedTerm(\"x\", types.type_e)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Future: IPython cell magic for metalanguage"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Terms: capital letters are constants, lower case are variables.  \n",
      "\n",
      "There is some convenience type guessing to make expressions shorter.  That is, '_Cat_' in the next cell does not have an explicit type and so the initial guess is t, but it realizes that the argument is type _e_ and so adjusts it up to _<e,t>_.  This form of type inference is not very general and really intended for convenience in writing expresssions like this.  (There are examples of the more general type inference system below.)\n",
      "\n",
      "To turn off notices about this form of type guessing, you can call _meta.logger.setLevel(meta.logging.WARNING)_ to raise the logging level, and _meta.logger.setLevel(meta.logging.INFO)_ to re-enable."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#meta.logger.setLevel(meta.logging.WARNING)\n",
      "te(\"Cat(x_e)\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x1 = te(\"L x_e: Cat(x)\")\n",
      "x2 = te(\"\u03bbx: Dog(x_e)\")\n",
      "\n",
      "ltx_print(x1, x2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cat_term = meta.CustomTerm(\"Cat\", typ=types.type_property)\n",
      "var = te(\"x_e\")\n",
      "cat_term(var)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(cat_term(var)).type"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cat_term.type"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Various convenience python operators are overloaded, including functional calls:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(cat_term(var) & te(\"p_t\")) >> te(\"q_t\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cat_fun = meta.LFun(types.type_e, cat_term(var), \"x\")\n",
      "cat_fun"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cat_fun(te(\"y_e\")) #.reduce()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Building a function-argument expression builds a complex, unreduced expression.  This can be explicitly reduced (note that the _reduce_all_ function applies this recursively):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cat_fun(te(\"y_e\")).reduce()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "_TypedExpr_ s in general consist of an operator followed by some number of arguments, possibly 0."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "P = TypedTerm(\"P\", types.FunType(type_e, type_t))\n",
      "Q = TypedTerm(\"Q\", types.FunType(type_e, type_t))\n",
      "x = TypedTerm(\"x\", type_e)\n",
      "y = TypedTerm(\"y\", type_e)\n",
      "t = TypedExpr.factory(P, x)\n",
      "t2 = TypedExpr.factory(Q, x)\n",
      "# shorter way: t = te(\"P(x_e)\")\n",
      "\n",
      "ltx_print(P, t2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Much shorter syntax exists for this in the form of a metalanguage parser."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "P = te(\"P_<e,t>\")\n",
      "x = te(\"x_e\")\n",
      "t = P(x)\n",
      "\n",
      "ltx_print(P, t2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Even simpler:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%lamb\n",
      "t = P_<e,t>(x_e)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# propositional variable\n",
      "p = TypedTerm(\"p\", type_t)\n",
      "\n",
      "pmw_test1 = LFun(type_t, LFun(type_e, t & p, \"x\"), \"p\")\n",
      "pmw_test1b = LFun(type_e, t & t2, \"x\")\n",
      "\n",
      "ltx_print(pmw_test1, pmw_test1.type,\n",
      "  pmw_test1b, pmw_test1b.type,\n",
      "  t2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pmw_test1(t2).reduce()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pmw_test1(x) # function is type <t<et>> so will trigger a type mismatch"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Same example in more straightforward metalanguage syntax:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%lamb\n",
      "test1 = L p_t : L x_e : P(x) & p\n",
      "test1b = L x_e : P(x) & Q(x)\n",
      "t2 = Q(x_e)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ltx_print(test1(t2), \n",
      "          test1(t2).reduce())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice that the variable _x_ is renamed to _x1_ to avoid conflict with the free _x_ in _t2_."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "&nbsp;\n",
      "\n",
      "## Part 3: composition systems for an object language ##\n",
      "\n",
      " * Focus on type-driven composition, current syntactic implementation fairly minimal\n",
      " * lots more to do here.\n",
      "\n",
      "Key class(/mixin): _Composable_.  Some key subclasses:\n",
      "\n",
      " * _Item_: representation of a lexical item\n",
      " * _BinaryComposite_: result of composing any two _Composables_ using a single composition method.  Inherits from _nltk.Tree_!\n",
      " * _CompositionResult_: result of composing any two _Composables_ -- may represent multiple possible composition paths\n",
      "\n",
      "Key class: _CompositionSystem_.  Describes a set of composition operations."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def demo_fa_fun(fun, arg, assignment=None):\n",
      "    if (not fun.type.functional()) or fun.type.left != arg.type:\n",
      "        raise TypeMismatch(fun, arg, \"Function Application\")\n",
      "    return lang.BinaryComposite(fun, arg, \n",
      "                (fun.content.under_assignment(assignment)(arg.content.under_assignment(assignment))).reduce())\n",
      "\n",
      "pm_op = lang.te(\"L f_<e,t> : L g_<e,t> : L x_e : f(x) & g(x)\")\n",
      "\n",
      "def demo_pm_fun(fun1, fun2, assignment=None):\n",
      "    \"\"\"H&K predicate modification -- restricted to type <et>.\"\"\"\n",
      "    ts = meta.get_type_system()\n",
      "    if not (ts.eq_check(fun1.type, types.type_property) and \n",
      "            ts.eq_check(fun2.type, types.type_property)):\n",
      "        raise TypeMismatch(fun1, fun2, \"Predicate Modification\")\n",
      "    #if fun1.type != fun2.type or fun1.type != type_property:\n",
      "    #    raise TypeMismatch(fun1, fun2, \"Predicate Modification\")\n",
      "    varname = fun1.content.varname\n",
      "    c1 = fun1.content.under_assignment(assignment)\n",
      "    c2 = fun2.content.under_assignment(assignment)\n",
      "    result = pm_op.apply(c1).apply(c2).reduce_all()\n",
      "    return lang.BinaryComposite(fun1, fun2, result)\n",
      "\n",
      "pm = lang.BinaryCompositionOp(\"PM\", demo_pm_fun, commutative=False)\n",
      "fa = lang.BinaryCompositionOp(\"FA\", demo_fa_fun)\n",
      "pa = lang.BinaryCompositionOp(\"PA\", lang.pa_fun, allow_none=True)\n",
      "demo_hk_system = lang.CompositionSystem(rules=[fa, pm, pa], basictypes={type_e, type_t})\n",
      "lang.set_system(demo_hk_system)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "meta.constants_use_custom(True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%lamb\n",
      "||cat|| = L x_e: Cat(x)\n",
      "||gray|| = L x_e: Gray(x)\n",
      "||john|| = John_e\n",
      "||julius|| = Julius_e\n",
      "||inP|| = L x_e : L y_e : In(y)(x)\n",
      "||texas|| = Texas_e\n",
      "||isV|| = L p_<e,t> : p"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# if you want to use H&K style metalanguage, there are various hooks for doing this.\n",
      "gray.content.args[0].op.custom = \"is\"\n",
      "inP.content.args[0].args[0].op.op.custom = \"is\"\n",
      "ltx_print(gray, inP)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the purely type-driven mode, composition is triggered by using the '*' operator on a composable."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "inP * texas"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sentence1 = julius * (isV * (inP * texas))\n",
      "sentence1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sentence1.full_trace_latex()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I have temporarily disabled the fact that standard PM is symmetric, to illustrated multiple composition paths:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gray * cat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gray * cat * (inP * texas)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = lang.Item(\"a\", lang.isV.content) # identity function for copula as well\n",
      "isV * (a * (gray * cat * (inP * texas)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np = ((gray * cat) * (inP * texas))\n",
      "vp = (isV * (a * np))\n",
      "sentence2 = julius * vp\n",
      "sentence2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "julius * isV # will fail due to type mismatches"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sentence2.full_trace_latex()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sentence1.results[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sentence1.results[0].latex_step_tree()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sentence2.results[0].latex_step_tree()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "One of the infamous examples from Heim and Kratzer (names different):\n",
      "\n",
      " * Julius is a gray cat in Texas fond of John."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fond = lang.Item(\"fond\", \"L x_e : L y_e : Fond(y)(x)\")\n",
      "ofP = lang.Item(\"of\", \"L x_e : x\")\n",
      "sentence3 = julius * (lang.isV * (a * (np * (fond * (ofP * lang.john)))))\n",
      "sentence3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sentence3.results[0].latex_step_tree()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The _Composite_ class subclasses _nltk.Tree_, and so supports the things that class does.  E.g. []-based paths:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "parse_tree3 = sentence3.results[0]\n",
      "parse_tree3[0][1][1].latex_step_tree()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some rudimentary support for traces."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "binder = lang.Item(\"23\", None)\n",
      "binder2 = lang.Item(\"5\", None)\n",
      "t = lang.Trace(23, types.type_e)\n",
      "t2 = lang.Trace(5)\n",
      "ltx_print(t, t2, binder)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "((t * gray))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b1 = (binder * (binder2 * (t * (lang.inP * t2))))\n",
      "b2 = (binder2 * (binder * (t * (lang.inP * t2))))\n",
      "ltx_print(b1, b2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b1.full_trace_latex()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "b1.results[0].latex_step_tree()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Composition in tree structures\n",
      "\n",
      "Current work: implementing tree-based computation, and top-down/deferred computation\n",
      "\n",
      "* using nltk Tree objects.\n",
      "* system for deferred / uncertain types -- basic inference over unknown types"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t2 = Tree(\"S\", [\"NP\", \"VP\"])\n",
      "r2 = lang.hk3_system.compose(t2)\n",
      "r2.latex_step_tree() #._repr_latex_()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from lamb.tree_mini import Tree # hacked package to work with python 3\n",
      "t = Tree(\"S\", [cat, \"VP\"])  # this is a tree with a missing VP.  Exploit the fact that Composites are trees and nodes can be Items in lamb.\n",
      "#local_tree = lang.tfa_l.build_local(t)\n",
      "#local_tree # need to implement ipython output routines for nltk.Tree.\n",
      "#lang.hk3_system.compose(t)\n",
      "t2 = lang.CompositionTree.tree_factory(t)\n",
      "t2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r = lang.hk3_system.compose(t)\n",
      "r"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r.latex_step_tree()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "&nbsp;\n",
      "\n",
      "## Some future projects, non-exhaustive ##\n",
      "\n",
      "* complete fragment of Heim and Kratzer\n",
      "* extend fragment coverage.  Some interesting targets where interactivity would be useful to understanding:\n",
      "  * Continuations and quantification (Cf. van Eijck and Unger's Haskell implementation)\n",
      "  * Jacobson-style analyses of pronouns\n",
      "  * Compositional hamblin semantics\n",
      "  * Compositional DRT\n",
      "* better inference over types.  (Standard algorithms from type-logical grammar?)\n",
      "* variables over types -- for type-flexible denotations.\n",
      "* type shifts.  (Quite easy in this framework.)\n",
      "* underlying model theory.\n",
      "* various improvements to the graphics -- trees (?), double brackets (hard in mathjax), ...\n",
      "* full latex output (trees in tikz-qtree and so on).\n",
      "* better set theory mechanisms\n",
      "* presuppositions and some form of projection (Starting point, Heim and Kratzer)\n",
      "\n",
      "Longer term:\n",
      "\n",
      "* integration with SymPy (?)\n",
      "* release as an app\n",
      "* deeper integration with nltk (once nltk is compatible with python 3)\n",
      "* parsing that makes less use of python `eval`, and is generally less ad-hoc.  (This is an issue inherited from AIMA-python's logic.py.)\n",
      "  * this is an issue where in principle, a language like Haskell is a better choice than python.  But I think the usability / robustness of python and its libraries has the edge here overall, not to mention ipython notebook...\n",
      "* toy spatial system\n",
      "* side-by-side comparison of e.g. multiple analyses of presupposition projection"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}